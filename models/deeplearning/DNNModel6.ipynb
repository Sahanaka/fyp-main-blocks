{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model 6 - text (word) to voice generation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOMPI6u0w+jIVkuR3u/DNLK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"HLe_rhrr09Tk","executionInfo":{"status":"error","timestamp":1624367495184,"user_tz":-330,"elapsed":597,"user":{"displayName":"P.A.D. Shehan Nilmantha Wijesekara","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8RfvZXKz84CXkRJ8-GnI8w2SRVGC02UWJlYMC=s64","userId":"02692999607457084522"}},"outputId":"5bfea9f8-165c-41ff-b509-4933ae8107ad"},"source":["from __future__ import print_function\n","\n","from hyperparams import Hyperparams as hp\n","import numpy as np\n","import tensorflow as tf\n","from utils import *\n","import codecs\n","import re\n","import os\n","import unicodedata\n","\n","def load_vocab():\n","    char2idx = {char: idx for idx, char in enumerate(hp.vocab)}\n","    idx2char = {idx: char for idx, char in enumerate(hp.vocab)}\n","    return char2idx, idx2char\n","\n","def text_normalize(text):\n","    text = ''.join(char for char in unicodedata.normalize('NFD', text)\n","                           if unicodedata.category(char) != 'Mn') # Strip accents\n","\n","    text = text.lower()\n","    text = re.sub(\"[^{}]\".format(hp.vocab), \" \", text)\n","    text = re.sub(\"[ ]+\", \" \", text)\n","    return text\n","\n","def load_data(mode=\"train\"):\n","    '''Loads data\n","      Args:\n","          mode: \"train\" or \"synthesize\".\n","    '''\n","    # Load vocabulary\n","    char2idx, idx2char = load_vocab()\n","\n","    if mode==\"train\":\n","        if \"LJ\" in hp.data:\n","            # Parse\n","            fpaths, text_lengths, texts = [], [], []\n","            transcript = os.path.join(hp.data, 'transcript.csv')\n","            lines = codecs.open(transcript, 'r', 'utf-8').readlines()\n","            for line in lines:\n","                fname, _, text = line.strip().split(\"|\")\n","\n","                fpath = os.path.join(hp.data, \"wavs\", fname + \".wav\")\n","                fpaths.append(fpath)\n","\n","                text = text_normalize(text) + \"E\"  # E: EOS\n","                text = [char2idx[char] for char in text]\n","                text_lengths.append(len(text))\n","                texts.append(np.array(text, np.int32).tostring())\n","\n","            return fpaths, text_lengths, texts\n","        else: # nick or kate\n","            # Parse\n","            fpaths, text_lengths, texts = [], [], []\n","            transcript = os.path.join(hp.data, 'transcript.csv')\n","            lines = codecs.open(transcript, 'r', 'utf-8').readlines()\n","            for line in lines:\n","                fname, _, text, is_inside_quotes, duration = line.strip().split(\"|\")\n","                duration = float(duration)\n","                if duration > 10. : continue\n","\n","                fpath = os.path.join(hp.data, fname)\n","                fpaths.append(fpath)\n","\n","                text += \"E\"  # E: EOS\n","                text = [char2idx[char] for char in text]\n","                text_lengths.append(len(text))\n","                texts.append(np.array(text, np.int32).tostring())\n","\n","        return fpaths, text_lengths, texts\n","\n","    else: # synthesize on unseen test text.\n","        # Parse\n","        lines = codecs.open(hp.test_data, 'r', 'utf-8').readlines()[1:]\n","        sents = [text_normalize(line.split(\" \", 1)[-1]).strip() + \"E\" for line in lines] # text normalization, E: EOS\n","        texts = np.zeros((len(sents), hp.max_N), np.int32)\n","        for i, sent in enumerate(sents):\n","            texts[i, :len(sent)] = [char2idx[char] for char in sent]\n","        return texts\n","\n","def get_batch():\n","    \"\"\"Loads training data and put them in queues\"\"\"\n","    with tf.device('/cpu:0'):\n","        # Load data\n","        fpaths, text_lengths, texts = load_data() # list\n","        maxlen, minlen = max(text_lengths), min(text_lengths)\n","\n","        # Calc total batch count\n","        num_batch = len(fpaths) // hp.B\n","\n","        # Create Queues\n","        fpath, text_length, text = tf.train.slice_input_producer([fpaths, text_lengths, texts], shuffle=True)\n","\n","        # Parse\n","        text = tf.decode_raw(text, tf.int32)  # (None,)\n","\n","        if hp.prepro:\n","            def _load_spectrograms(fpath):\n","                fname = os.path.basename(fpath)\n","                mel = \"mels/{}\".format(fname.replace(\"wav\", \"npy\"))\n","                mag = \"mags/{}\".format(fname.replace(\"wav\", \"npy\"))\n","                return fname, np.load(mel), np.load(mag)\n","\n","            fname, mel, mag = tf.py_func(_load_spectrograms, [fpath], [tf.string, tf.float32, tf.float32])\n","        else:\n","            fname, mel, mag = tf.py_func(load_spectrograms, [fpath], [tf.string, tf.float32, tf.float32])  # (None, n_mels)\n","\n","        # Add shape information\n","        fname.set_shape(())\n","        text.set_shape((None,))\n","        mel.set_shape((None, hp.n_mels))\n","        mag.set_shape((None, hp.n_fft//2+1))\n","\n","        # Batching\n","        _, (texts, mels, mags, fnames) = tf.contrib.training.bucket_by_sequence_length(\n","                                            input_length=text_length,\n","                                            tensors=[text, mel, mag, fname],\n","                                            batch_size=hp.B,\n","                                            bucket_boundaries=[i for i in range(minlen + 1, maxlen - 1, 20)],\n","                                            num_threads=8,\n","                                            capacity=hp.B*4,\n","                                            dynamic_pad=True)\n","\n","    return texts, mels, mags, fnames, num_batch\n"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c9814e68bded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperparams\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperparams'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"XasyrKYJ1BhO"},"source":["# -*- coding: utf-8 -*-\n","#/usr/bin/python2\n","'''\n","By kyubyong park. kbpark.linguist@gmail.com. \n","https://www.github.com/kyubyong/dc_tts\n","'''\n","class Hyperparams:\n","    '''Hyper parameters'''\n","    # pipeline\n","    prepro = True  # if True, run `python prepro.py` first before running `python train.py`.\n","    \n","    # signal processing\n","    sr = 22050  # Sampling rate.\n","    n_fft = 2048  # fft points (samples)\n","    frame_shift = 0.0125  # seconds\n","    frame_length = 0.05  # seconds\n","    hop_length = int(sr * frame_shift)  # samples. =276.\n","    win_length = int(sr * frame_length)  # samples. =1102.\n","    n_mels = 80  # Number of Mel banks to generate\n","    power = 1.5  # Exponent for amplifying the predicted magnitude\n","    n_iter = 50  # Number of inversion iterations\n","    preemphasis = .97\n","    max_db = 100\n","    ref_db = 20\n","\n","    # Model\n","    r = 4 # Reduction factor. Do not change this.\n","    dropout_rate = 0.05\n","    e = 128 # == embedding\n","    d = 256 # == hidden units of Text2Mel\n","    c = 512 # == hidden units of SSRN\n","    attention_win_size = 3\n","\n","    # data\n","    data = \"/data/private/voice/LJSpeech-1.0\"\n","    # data = \"/data/private/voice/kate\"\n","    test_data = 'harvard_sentences.txt'\n","    vocab = \"PE abcdefghijklmnopqrstuvwxyz'.?\" # P: Padding, E: EOS.\n","    max_N = 180 # Maximum number of characters.\n","    max_T = 210 # Maximum number of mel frames.\n","\n","    # training scheme\n","    lr = 0.001 # Initial learning rate.\n","    logdir = \"logdir/LJ01\"\n","    sampledir = 'samples'\n","    B = 32 # batch size\n","    num_iterations = 2000000\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkMEiHKg1Oac"},"source":["# -*- coding: utf-8 -*-\n","#/usr/bin/python2\n","'''\n","By kyubyong park. kbpark.linguist@gmail.com. \n","https://www.github.com/kyubyong/dc_tts\n","'''\n","\n","from __future__ import print_function, division\n","\n","import tensorflow as tf\n","\n","\n","def embed(inputs, vocab_size, num_units, zero_pad=True, scope=\"embedding\", reuse=None):\n","    '''Embeds a given tensor. \n","    \n","    Args:\n","      inputs: A `Tensor` with type `int32` or `int64` containing the ids\n","         to be looked up in `lookup table`.\n","      vocab_size: An int. Vocabulary size.\n","      num_units: An int. Number of embedding hidden units.\n","      zero_pad: A boolean. If True, all the values of the fist row (id 0)\n","        should be constant zeros.\n","      scope: Optional scope for `variable_scope`.  \n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","        \n","    Returns:\n","      A `Tensor` with one more rank than inputs's. The last dimensionality\n","        should be `num_units`.\n","    '''\n","    with tf.variable_scope(scope, reuse=reuse):\n","        lookup_table = tf.get_variable('lookup_table', \n","                                       dtype=tf.float32, \n","                                       shape=[vocab_size, num_units],\n","                                       initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n","        if zero_pad:\n","            lookup_table = tf.concat((tf.zeros(shape=[1, num_units]), \n","                                      lookup_table[1:, :]), 0)\n","\n","        outputs = tf.nn.embedding_lookup(lookup_table, inputs)\n","\n","    return outputs\n","\n","\n","def normalize(inputs,\n","              scope=\"normalize\",\n","              reuse=None):\n","    '''Applies layer normalization that normalizes along the last axis.\n","\n","    Args:\n","      inputs: A tensor with 2 or more dimensions, where the first dimension has\n","        `batch_size`. The normalization is over the last dimension.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","\n","    Returns:\n","      A tensor with the same shape and data dtype as `inputs`.\n","    '''\n","    outputs = tf.contrib.layers.layer_norm(inputs,\n","                                           begin_norm_axis=-1,\n","                                           scope=scope,\n","                                           reuse=reuse)\n","    return outputs\n","\n","\n","def highwaynet(inputs, num_units=None, scope=\"highwaynet\", reuse=None):\n","    '''Highway networks, see https://arxiv.org/abs/1505.00387\n","\n","    Args:\n","      inputs: A 3D tensor of shape [N, T, W].\n","      num_units: An int or `None`. Specifies the number of units in the highway layer\n","             or uses the input size if `None`.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","\n","    Returns:\n","      A 3D tensor of shape [N, T, W].\n","    '''\n","    if not num_units:\n","        num_units = inputs.get_shape()[-1]\n","\n","    with tf.variable_scope(scope, reuse=reuse):\n","        H = tf.layers.dense(inputs, units=num_units, activation=tf.nn.relu, name=\"dense1\")\n","        T = tf.layers.dense(inputs, units=num_units, activation=tf.nn.sigmoid,\n","                            bias_initializer=tf.constant_initializer(-1.0), name=\"dense2\")\n","        outputs = H * T + inputs * (1. - T)\n","    return outputs\n","\n","def conv1d(inputs,\n","           filters=None,\n","           size=1,\n","           rate=1,\n","           padding=\"SAME\",\n","           dropout_rate=0,\n","           use_bias=True,\n","           activation_fn=None,\n","           training=True,\n","           scope=\"conv1d\",\n","           reuse=None):\n","    '''\n","    Args:\n","      inputs: A 3-D tensor with shape of [batch, time, depth].\n","      filters: An int. Number of outputs (=activation maps)\n","      size: An int. Filter size.\n","      rate: An int. Dilation rate.\n","      padding: Either `same` or `valid` or `causal` (case-insensitive).\n","      dropout_rate: A float of [0, 1].\n","      use_bias: A boolean.\n","      activation_fn: A string.\n","      training: A boolean. If True, dropout is applied.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","\n","    Returns:\n","      A masked tensor of the same shape and dtypes as `inputs`.\n","    '''\n","    with tf.variable_scope(scope):\n","        if padding.lower() == \"causal\":\n","            # pre-padding for causality\n","            pad_len = (size - 1) * rate  # padding size\n","            inputs = tf.pad(inputs, [[0, 0], [pad_len, 0], [0, 0]])\n","            padding = \"valid\"\n","\n","        if filters is None:\n","            filters = inputs.get_shape().as_list()[-1]\n","\n","        params = {\"inputs\": inputs, \"filters\": filters, \"kernel_size\": size,\n","                  \"dilation_rate\": rate, \"padding\": padding, \"use_bias\": use_bias,\n","                  \"kernel_initializer\": tf.contrib.layers.variance_scaling_initializer(), \"reuse\": reuse}\n","\n","        tensor = tf.layers.conv1d(**params)\n","        tensor = normalize(tensor)\n","        if activation_fn is not None:\n","            tensor = activation_fn(tensor)\n","\n","        tensor = tf.layers.dropout(tensor, rate=dropout_rate, training=training)\n","\n","    return tensor\n","\n","def hc(inputs,\n","       filters=None,\n","       size=1,\n","       rate=1,\n","       padding=\"SAME\",\n","       dropout_rate=0,\n","       use_bias=True,\n","       activation_fn=None,\n","       training=True,\n","       scope=\"hc\",\n","       reuse=None):\n","    '''\n","    Args:\n","      inputs: A 3-D tensor with shape of [batch, time, depth].\n","      filters: An int. Number of outputs (=activation maps)\n","      size: An int. Filter size.\n","      rate: An int. Dilation rate.\n","      padding: Either `same` or `valid` or `causal` (case-insensitive).\n","      use_bias: A boolean.\n","      activation_fn: A string.\n","      training: A boolean. If True, dropout is applied.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","\n","    Returns:\n","      A masked tensor of the same shape and dtypes as `inputs`.\n","    '''\n","    _inputs = inputs\n","    with tf.variable_scope(scope):\n","        if padding.lower() == \"causal\":\n","            # pre-padding for causality\n","            pad_len = (size - 1) * rate  # padding size\n","            inputs = tf.pad(inputs, [[0, 0], [pad_len, 0], [0, 0]])\n","            padding = \"valid\"\n","\n","        if filters is None:\n","            filters = inputs.get_shape().as_list()[-1]\n","\n","\n","        params = {\"inputs\": inputs, \"filters\": 2*filters, \"kernel_size\": size,\n","                  \"dilation_rate\": rate, \"padding\": padding, \"use_bias\": use_bias,\n","                  \"kernel_initializer\": tf.contrib.layers.variance_scaling_initializer(), \"reuse\": reuse}\n","\n","        tensor = tf.layers.conv1d(**params)\n","        H1, H2 = tf.split(tensor, 2, axis=-1)\n","        H1 = normalize(H1, scope=\"H1\")\n","        H2 = normalize(H2, scope=\"H2\")\n","        H1 = tf.nn.sigmoid(H1, \"gate\")\n","        H2 = activation_fn(H2, \"info\") if activation_fn is not None else H2\n","        tensor = H1*H2 + (1.-H1)*_inputs\n","\n","        tensor = tf.layers.dropout(tensor, rate=dropout_rate, training=training)\n","\n","    return tensor\n","\n","def conv1d_transpose(inputs,\n","                     filters=None,\n","                     size=3,\n","                     stride=2,\n","                     padding='same',\n","                     dropout_rate=0,\n","                     use_bias=True,\n","                     activation=None,\n","                     training=True,\n","                     scope=\"conv1d_transpose\",\n","                     reuse=None):\n","    '''\n","        Args:\n","          inputs: A 3-D tensor with shape of [batch, time, depth].\n","          filters: An int. Number of outputs (=activation maps)\n","          size: An int. Filter size.\n","          rate: An int. Dilation rate.\n","          padding: Either `same` or `valid` or `causal` (case-insensitive).\n","          dropout_rate: A float of [0, 1].\n","          use_bias: A boolean.\n","          activation_fn: A string.\n","          training: A boolean. If True, dropout is applied.\n","          scope: Optional scope for `variable_scope`.\n","          reuse: Boolean, whether to reuse the weights of a previous layer\n","            by the same name.\n","\n","        Returns:\n","          A tensor of the shape with [batch, time*2, depth].\n","        '''\n","    with tf.variable_scope(scope, reuse=reuse):\n","        if filters is None:\n","            filters = inputs.get_shape().as_list()[-1]\n","        inputs = tf.expand_dims(inputs, 1)\n","        tensor = tf.layers.conv2d_transpose(inputs,\n","                                   filters=filters,\n","                                   kernel_size=(1, size),\n","                                   strides=(1, stride),\n","                                   padding=padding,\n","                                   activation=None,\n","                                   kernel_initializer=tf.contrib.layers.variance_scaling_initializer(),\n","                                   use_bias=use_bias)\n","        tensor = tf.squeeze(tensor, 1)\n","        tensor = normalize(tensor)\n","        if activation is not None:\n","            tensor = activation(tensor)\n","\n","        tensor = tf.layers.dropout(tensor, rate=dropout_rate, training=training)\n","\n","    return tensor\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slnEfi7H1W5x"},"source":["# -*- coding: utf-8 -*-\n","#/usr/bin/python2\n","'''\n","By kyubyong park. kbpark.linguist@gmail.com. \n","https://www.github.com/kyubyong/dc_tts\n","'''\n","\n","from __future__ import print_function\n","\n","from hyperparams import Hyperparams as hp\n","from modules import *\n","import tensorflow as tf\n","\n","def TextEnc(L, training=True):\n","    '''\n","    Args:\n","      L: Text inputs. (B, N)\n","\n","    Return:\n","        K: Keys. (B, N, d)\n","        V: Values. (B, N, d)\n","    '''\n","    i = 1\n","    tensor = embed(L,\n","                   vocab_size=len(hp.vocab),\n","                   num_units=hp.e,\n","                   scope=\"embed_{}\".format(i)); i += 1\n","    tensor = conv1d(tensor,\n","                    filters=2*hp.d,\n","                    size=1,\n","                    rate=1,\n","                    dropout_rate=hp.dropout_rate,\n","                    activation_fn=tf.nn.relu,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    tensor = conv1d(tensor,\n","                    size=1,\n","                    rate=1,\n","                    dropout_rate=hp.dropout_rate,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","\n","    for _ in range(2):\n","        for j in range(4):\n","            tensor = hc(tensor,\n","                            size=3,\n","                            rate=3**j,\n","                            dropout_rate=hp.dropout_rate,\n","                            activation_fn=None,\n","                            training=training,\n","                            scope=\"HC_{}\".format(i)); i += 1\n","    for _ in range(2):\n","        tensor = hc(tensor,\n","                        size=3,\n","                        rate=1,\n","                        dropout_rate=hp.dropout_rate,\n","                        activation_fn=None,\n","                        training=training,\n","                        scope=\"HC_{}\".format(i)); i += 1\n","\n","    for _ in range(2):\n","        tensor = hc(tensor,\n","                        size=1,\n","                        rate=1,\n","                        dropout_rate=hp.dropout_rate,\n","                        activation_fn=None,\n","                        training=training,\n","                        scope=\"HC_{}\".format(i)); i += 1\n","\n","    K, V = tf.split(tensor, 2, -1)\n","    return K, V\n","\n","def AudioEnc(S, training=True):\n","    '''\n","    Args:\n","      S: melspectrogram. (B, T/r, n_mels)\n","\n","    Returns\n","      Q: Queries. (B, T/r, d)\n","    '''\n","    i = 1\n","    tensor = conv1d(S,\n","                    filters=hp.d,\n","                    size=1,\n","                    rate=1,\n","                    padding=\"CAUSAL\",\n","                    dropout_rate=hp.dropout_rate,\n","                    activation_fn=tf.nn.relu,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    tensor = conv1d(tensor,\n","                    size=1,\n","                    rate=1,\n","                    padding=\"CAUSAL\",\n","                    dropout_rate=hp.dropout_rate,\n","                    activation_fn=tf.nn.relu,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    tensor = conv1d(tensor,\n","                    size=1,\n","                    rate=1,\n","                    padding=\"CAUSAL\",\n","                    dropout_rate=hp.dropout_rate,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    for _ in range(2):\n","        for j in range(4):\n","            tensor = hc(tensor,\n","                            size=3,\n","                            rate=3**j,\n","                            padding=\"CAUSAL\",\n","                            dropout_rate=hp.dropout_rate,\n","                            training=training,\n","                            scope=\"HC_{}\".format(i)); i += 1\n","    for _ in range(2):\n","        tensor = hc(tensor,\n","                        size=3,\n","                        rate=3,\n","                        padding=\"CAUSAL\",\n","                        dropout_rate=hp.dropout_rate,\n","                        training=training,\n","                        scope=\"HC_{}\".format(i)); i += 1\n","\n","    return tensor\n","\n","def Attention(Q, K, V, mononotic_attention=False, prev_max_attentions=None):\n","    '''\n","    Args:\n","      Q: Queries. (B, T/r, d)\n","      K: Keys. (B, N, d)\n","      V: Values. (B, N, d)\n","      mononotic_attention: A boolean. At training, it is False.\n","      prev_max_attentions: (B,). At training, it is set to None.\n","\n","    Returns:\n","      R: [Context Vectors; Q]. (B, T/r, 2d)\n","      alignments: (B, N, T/r)\n","      max_attentions: (B, T/r)\n","    '''\n","    A = tf.matmul(Q, K, transpose_b=True) * tf.rsqrt(tf.to_float(hp.d))\n","    if mononotic_attention:  # for inference\n","        key_masks = tf.sequence_mask(prev_max_attentions, hp.max_N)\n","        reverse_masks = tf.sequence_mask(hp.max_N - hp.attention_win_size - prev_max_attentions, hp.max_N)[:, ::-1]\n","        masks = tf.logical_or(key_masks, reverse_masks)\n","        masks = tf.tile(tf.expand_dims(masks, 1), [1, hp.max_T, 1])\n","        paddings = tf.ones_like(A) * (-2 ** 32 + 1)  # (B, T/r, N)\n","        A = tf.where(tf.equal(masks, False), A, paddings)\n","    A = tf.nn.softmax(A) # (B, T/r, N)\n","    max_attentions = tf.argmax(A, -1)  # (B, T/r)\n","    R = tf.matmul(A, V)\n","    R = tf.concat((R, Q), -1)\n","\n","    alignments = tf.transpose(A, [0, 2, 1]) # (B, N, T/r)\n","\n","    return R, alignments, max_attentions\n","\n","def AudioDec(R, training=True):\n","    '''\n","    Args:\n","      R: [Context Vectors; Q]. (B, T/r, 2d)\n","\n","    Returns:\n","      Y: Melspectrogram predictions. (B, T/r, n_mels)\n","    '''\n","\n","    i = 1\n","    tensor = conv1d(R,\n","                    filters=hp.d,\n","                    size=1,\n","                    rate=1,\n","                    padding=\"CAUSAL\",\n","                    dropout_rate=hp.dropout_rate,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    for j in range(4):\n","        tensor = hc(tensor,\n","                        size=3,\n","                        rate=3**j,\n","                        padding=\"CAUSAL\",\n","                        dropout_rate=hp.dropout_rate,\n","                        training=training,\n","                        scope=\"HC_{}\".format(i)); i += 1\n","\n","    for _ in range(2):\n","        tensor = hc(tensor,\n","                        size=3,\n","                        rate=1,\n","                        padding=\"CAUSAL\",\n","                        dropout_rate=hp.dropout_rate,\n","                        training=training,\n","                        scope=\"HC_{}\".format(i)); i += 1\n","    for _ in range(3):\n","        tensor = conv1d(tensor,\n","                        size=1,\n","                        rate=1,\n","                        padding=\"CAUSAL\",\n","                        dropout_rate=hp.dropout_rate,\n","                        activation_fn=tf.nn.relu,\n","                        training=training,\n","                        scope=\"C_{}\".format(i)); i += 1\n","    # mel_hats\n","    logits = conv1d(tensor,\n","                    filters=hp.n_mels,\n","                    size=1,\n","                    rate=1,\n","                    padding=\"CAUSAL\",\n","                    dropout_rate=hp.dropout_rate,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    Y = tf.nn.sigmoid(logits) # mel_hats\n","\n","    return logits, Y\n","\n","def SSRN(Y, training=True):\n","    '''\n","    Args:\n","      Y: Melspectrogram Predictions. (B, T/r, n_mels)\n","\n","    Returns:\n","      Z: Spectrogram Predictions. (B, T, 1+n_fft/2)\n","    '''\n","\n","    i = 1 # number of layers\n","\n","    # -> (B, T/r, c)\n","    tensor = conv1d(Y,\n","                    filters=hp.c,\n","                    size=1,\n","                    rate=1,\n","                    dropout_rate=hp.dropout_rate,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    for j in range(2):\n","        tensor = hc(tensor,\n","                      size=3,\n","                      rate=3**j,\n","                      dropout_rate=hp.dropout_rate,\n","                      training=training,\n","                      scope=\"HC_{}\".format(i)); i += 1\n","    for _ in range(2):\n","        # -> (B, T/2, c) -> (B, T, c)\n","        tensor = conv1d_transpose(tensor,\n","                                  scope=\"D_{}\".format(i),\n","                                  dropout_rate=hp.dropout_rate,\n","                                  training=training,); i += 1\n","        for j in range(2):\n","            tensor = hc(tensor,\n","                            size=3,\n","                            rate=3**j,\n","                            dropout_rate=hp.dropout_rate,\n","                            training=training,\n","                            scope=\"HC_{}\".format(i)); i += 1\n","    # -> (B, T, 2*c)\n","    tensor = conv1d(tensor,\n","                    filters=2*hp.c,\n","                    size=1,\n","                    rate=1,\n","                    dropout_rate=hp.dropout_rate,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","    for _ in range(2):\n","        tensor = hc(tensor,\n","                        size=3,\n","                        rate=1,\n","                        dropout_rate=hp.dropout_rate,\n","                        training=training,\n","                        scope=\"HC_{}\".format(i)); i += 1\n","    # -> (B, T, 1+n_fft/2)\n","    tensor = conv1d(tensor,\n","                    filters=1+hp.n_fft//2,\n","                    size=1,\n","                    rate=1,\n","                    dropout_rate=hp.dropout_rate,\n","                    training=training,\n","                    scope=\"C_{}\".format(i)); i += 1\n","\n","    for _ in range(2):\n","        tensor = conv1d(tensor,\n","                        size=1,\n","                        rate=1,\n","                        dropout_rate=hp.dropout_rate,\n","                        activation_fn=tf.nn.relu,\n","                        training=training,\n","                        scope=\"C_{}\".format(i)); i += 1\n","    logits = conv1d(tensor,\n","               size=1,\n","               rate=1,\n","               dropout_rate=hp.dropout_rate,\n","               training=training,\n","               scope=\"C_{}\".format(i))\n","    Z = tf.nn.sigmoid(logits)\n","    return logits, Z\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"_HJwo3YE1f8s","executionInfo":{"status":"error","timestamp":1624367337169,"user_tz":-330,"elapsed":1611,"user":{"displayName":"P.A.D. Shehan Nilmantha Wijesekara","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8RfvZXKz84CXkRJ8-GnI8w2SRVGC02UWJlYMC=s64","userId":"02692999607457084522"}},"outputId":"58155623-f4a3-4aca-f322-3e2810889a75"},"source":["# -*- coding: utf-8 -*-\n","#/usr/bin/python2\n","'''\n","By kyubyong park. kbpark.linguist@gmail.com.\n","https://www.github.com/kyubyong/dc_tts\n","'''\n","\n","from __future__ import print_function\n","\n","from utils import load_spectrograms\n","import os\n","from data_load import load_data\n","import numpy as np\n","import tqdm\n","\n","# Load data\n","fpaths, _, _ = load_data() # list\n","\n","for fpath in tqdm.tqdm(fpaths):\n","    fname, mel, mag = load_spectrograms(fpath)\n","    if not os.path.exists(\"mels\"): os.mkdir(\"mels\")\n","    if not os.path.exists(\"mags\"): os.mkdir(\"mags\")\n","\n","    np.save(\"mels/{}\".format(fname.replace(\"wav\", \"npy\")), mel)\n","    np.save(\"mags/{}\".format(fname.replace(\"wav\", \"npy\")), mag)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2cfc76d2f269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_spectrograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_load\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"lTo-V-Bi1rry"},"source":["# -*- coding: utf-8 -*-\n","# /usr/bin/python2\n","'''\n","By kyubyong park. kbpark.linguist@gmail.com.\n","https://www.github.com/kyubyong/dc_tts\n","'''\n","\n","from __future__ import print_function\n","\n","import os\n","\n","from hyperparams import Hyperparams as hp\n","import numpy as np\n","import tensorflow as tf\n","from train import Graph\n","from utils import *\n","from data_load import load_data\n","from scipy.io.wavfile import write\n","from tqdm import tqdm\n","\n","def synthesize():\n","    # Load data\n","    L = load_data(\"synthesize\")\n","\n","    # Load graph\n","    g = Graph(mode=\"synthesize\"); print(\"Graph loaded\")\n","\n","    with tf.Session() as sess:\n","        sess.run(tf.global_variables_initializer())\n","\n","        # Restore parameters\n","        var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'Text2Mel')\n","        saver1 = tf.train.Saver(var_list=var_list)\n","        saver1.restore(sess, tf.train.latest_checkpoint(hp.logdir + \"-1\"))\n","        print(\"Text2Mel Restored!\")\n","\n","        var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SSRN') + \\\n","                   tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gs')\n","        saver2 = tf.train.Saver(var_list=var_list)\n","        saver2.restore(sess, tf.train.latest_checkpoint(hp.logdir + \"-2\"))\n","        print(\"SSRN Restored!\")\n","\n","        # Feed Forward\n","        ## mel\n","        Y = np.zeros((len(L), hp.max_T, hp.n_mels), np.float32)\n","        prev_max_attentions = np.zeros((len(L),), np.int32)\n","        for j in tqdm(range(hp.max_T)):\n","            _gs, _Y, _max_attentions, _alignments = \\\n","                sess.run([g.global_step, g.Y, g.max_attentions, g.alignments],\n","                         {g.L: L,\n","                          g.mels: Y,\n","                          g.prev_max_attentions: prev_max_attentions})\n","            Y[:, j, :] = _Y[:, j, :]\n","            prev_max_attentions = _max_attentions[:, j]\n","\n","        # Get magnitude\n","        Z = sess.run(g.Z, {g.Y: Y})\n","\n","        # Generate wav files\n","        if not os.path.exists(hp.sampledir): os.makedirs(hp.sampledir)\n","        for i, mag in enumerate(Z):\n","            print(\"Working on file\", i+1)\n","            wav = spectrogram2wav(mag)\n","            write(hp.sampledir + \"/{}.wav\".format(i+1), hp.sr, wav)\n","\n","if __name__ == '__main__':\n","    synthesize()\n","    print(\"Done\")\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7RGCC4R1yId"},"source":["# -*- coding: utf-8 -*-\n","# /usr/bin/python2\n","'''\n","By kyubyong park. kbpark.linguist@gmail.com. \n","https://www.github.com/kyubyong/dc_tts\n","'''\n","\n","from __future__ import print_function\n","\n","from tqdm import tqdm\n","\n","from data_load import get_batch, load_vocab\n","from hyperparams import Hyperparams as hp\n","from modules import *\n","from networks import TextEnc, AudioEnc, AudioDec, Attention, SSRN\n","import tensorflow as tf\n","from utils import *\n","import sys\n","\n","\n","class Graph:\n","    def __init__(self, num=1, mode=\"train\"):\n","        '''\n","        Args:\n","          num: Either 1 or 2. 1 for Text2Mel 2 for SSRN.\n","          mode: Either \"train\" or \"synthesize\".\n","        '''\n","        # Load vocabulary\n","        self.char2idx, self.idx2char = load_vocab()\n","\n","        # Set flag\n","        training = True if mode==\"train\" else False\n","\n","        # Graph\n","        # Data Feeding\n","        ## L: Text. (B, N), int32\n","        ## mels: Reduced melspectrogram. (B, T/r, n_mels) float32\n","        ## mags: Magnitude. (B, T, n_fft//2+1) float32\n","        if mode==\"train\":\n","            self.L, self.mels, self.mags, self.fnames, self.num_batch = get_batch()\n","            self.prev_max_attentions = tf.ones(shape=(hp.B,), dtype=tf.int32)\n","            self.gts = tf.convert_to_tensor(guided_attention())\n","        else:  # Synthesize\n","            self.L = tf.placeholder(tf.int32, shape=(None, None))\n","            self.mels = tf.placeholder(tf.float32, shape=(None, None, hp.n_mels))\n","            self.prev_max_attentions = tf.placeholder(tf.int32, shape=(None,))\n","\n","        if num==1 or (not training):\n","            with tf.variable_scope(\"Text2Mel\"):\n","                # Get S or decoder inputs. (B, T//r, n_mels)\n","                self.S = tf.concat((tf.zeros_like(self.mels[:, :1, :]), self.mels[:, :-1, :]), 1)\n","\n","                # Networks\n","                with tf.variable_scope(\"TextEnc\"):\n","                    self.K, self.V = TextEnc(self.L, training=training)  # (N, Tx, e)\n","\n","                with tf.variable_scope(\"AudioEnc\"):\n","                    self.Q = AudioEnc(self.S, training=training)\n","\n","                with tf.variable_scope(\"Attention\"):\n","                    # R: (B, T/r, 2d)\n","                    # alignments: (B, N, T/r)\n","                    # max_attentions: (B,)\n","                    self.R, self.alignments, self.max_attentions = Attention(self.Q, self.K, self.V,\n","                                                                             mononotic_attention=(not training),\n","                                                                             prev_max_attentions=self.prev_max_attentions)\n","                with tf.variable_scope(\"AudioDec\"):\n","                    self.Y_logits, self.Y = AudioDec(self.R, training=training) # (B, T/r, n_mels)\n","        else:  # num==2 & training. Note that during training,\n","            # the ground truth melspectrogram values are fed.\n","            with tf.variable_scope(\"SSRN\"):\n","                self.Z_logits, self.Z = SSRN(self.mels, training=training)\n","\n","        if not training:\n","            # During inference, the predicted melspectrogram values are fed.\n","            with tf.variable_scope(\"SSRN\"):\n","                self.Z_logits, self.Z = SSRN(self.Y, training=training)\n","\n","        with tf.variable_scope(\"gs\"):\n","            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n","\n","        if training:\n","            if num==1: # Text2Mel\n","                # mel L1 loss\n","                self.loss_mels = tf.reduce_mean(tf.abs(self.Y - self.mels))\n","\n","                # mel binary divergence loss\n","                self.loss_bd1 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.Y_logits, labels=self.mels))\n","\n","                # guided_attention loss\n","                self.A = tf.pad(self.alignments, [(0, 0), (0, hp.max_N), (0, hp.max_T)], mode=\"CONSTANT\", constant_values=-1.)[:, :hp.max_N, :hp.max_T]\n","                self.attention_masks = tf.to_float(tf.not_equal(self.A, -1))\n","                self.loss_att = tf.reduce_sum(tf.abs(self.A * self.gts) * self.attention_masks)\n","                self.mask_sum = tf.reduce_sum(self.attention_masks)\n","                self.loss_att /= self.mask_sum\n","\n","                # total loss\n","                self.loss = self.loss_mels + self.loss_bd1 + self.loss_att\n","\n","                tf.summary.scalar('train/loss_mels', self.loss_mels)\n","                tf.summary.scalar('train/loss_bd1', self.loss_bd1)\n","                tf.summary.scalar('train/loss_att', self.loss_att)\n","                tf.summary.image('train/mel_gt', tf.expand_dims(tf.transpose(self.mels[:1], [0, 2, 1]), -1))\n","                tf.summary.image('train/mel_hat', tf.expand_dims(tf.transpose(self.Y[:1], [0, 2, 1]), -1))\n","            else: # SSRN\n","                # mag L1 loss\n","                self.loss_mags = tf.reduce_mean(tf.abs(self.Z - self.mags))\n","\n","                # mag binary divergence loss\n","                self.loss_bd2 = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.Z_logits, labels=self.mags))\n","\n","                # total loss\n","                self.loss = self.loss_mags + self.loss_bd2\n","\n","                tf.summary.scalar('train/loss_mags', self.loss_mags)\n","                tf.summary.scalar('train/loss_bd2', self.loss_bd2)\n","                tf.summary.image('train/mag_gt', tf.expand_dims(tf.transpose(self.mags[:1], [0, 2, 1]), -1))\n","                tf.summary.image('train/mag_hat', tf.expand_dims(tf.transpose(self.Z[:1], [0, 2, 1]), -1))\n","\n","            # Training Scheme\n","            self.lr = learning_rate_decay(hp.lr, self.global_step)\n","            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n","            tf.summary.scalar(\"lr\", self.lr)\n","\n","            ## gradient clipping\n","            self.gvs = self.optimizer.compute_gradients(self.loss)\n","            self.clipped = []\n","            for grad, var in self.gvs:\n","                grad = tf.clip_by_value(grad, -1., 1.)\n","                self.clipped.append((grad, var))\n","                self.train_op = self.optimizer.apply_gradients(self.clipped, global_step=self.global_step)\n","\n","            # Summary\n","            self.merged = tf.summary.merge_all()\n","\n","\n","if __name__ == '__main__':\n","    # argument: 1 or 2. 1 for Text2mel, 2 for SSRN.\n","    num = int(sys.argv[1])\n","\n","    g = Graph(num=num); print(\"Training Graph loaded\")\n","\n","    logdir = hp.logdir + \"-\" + str(num)\n","    sv = tf.train.Supervisor(logdir=logdir, save_model_secs=0, global_step=g.global_step)\n","    with sv.managed_session() as sess:\n","        while 1:\n","            for _ in tqdm(range(g.num_batch), total=g.num_batch, ncols=70, leave=False, unit='b'):\n","                gs, _ = sess.run([g.global_step, g.train_op])\n","\n","                # Write checkpoint files at every 1k steps\n","                if gs % 1000 == 0:\n","                    sv.saver.save(sess, logdir + '/model_gs_{}'.format(str(gs // 1000).zfill(3) + \"k\"))\n","\n","                    if num==1:\n","                        # plot alignment\n","                        alignments = sess.run(g.alignments)\n","                        plot_alignment(alignments[0], str(gs // 1000).zfill(3) + \"k\", logdir)\n","\n","                # break\n","                if gs > hp.num_iterations: break\n","\n","    print(\"Done\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"XNTqGTkT12-f","executionInfo":{"status":"error","timestamp":1624367419055,"user_tz":-330,"elapsed":4231,"user":{"displayName":"P.A.D. Shehan Nilmantha Wijesekara","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh8RfvZXKz84CXkRJ8-GnI8w2SRVGC02UWJlYMC=s64","userId":"02692999607457084522"}},"outputId":"7a4159ee-d26a-4284-efbe-b174d4e82a10"},"source":["# -*- coding: utf-8 -*-\n","#/usr/bin/python2\n","'''\n","By kyubyong park. kbpark.linguist@gmail.com. \n","https://www.github.com/kyubyong/dc_tts\n","'''\n","from __future__ import print_function, division\n","\n","import numpy as np\n","import librosa\n","import os, copy\n","import matplotlib\n","matplotlib.use('pdf')\n","import matplotlib.pyplot as plt\n","from scipy import signal\n","\n","from hyperparams import Hyperparams as hp\n","import tensorflow as tf\n","\n","def get_spectrograms(fpath):\n","    '''Parse the wave file in `fpath` and\n","    Returns normalized melspectrogram and linear spectrogram.\n","\n","    Args:\n","      fpath: A string. The full path of a sound file.\n","\n","    Returns:\n","      mel: A 2d array of shape (T, n_mels) and dtype of float32.\n","      mag: A 2d array of shape (T, 1+n_fft/2) and dtype of float32.\n","    '''\n","    # Loading sound file\n","    y, sr = librosa.load(fpath, sr=hp.sr)\n","\n","    # Trimming\n","    y, _ = librosa.effects.trim(y)\n","\n","    # Preemphasis\n","    y = np.append(y[0], y[1:] - hp.preemphasis * y[:-1])\n","\n","    # stft\n","    linear = librosa.stft(y=y,\n","                          n_fft=hp.n_fft,\n","                          hop_length=hp.hop_length,\n","                          win_length=hp.win_length)\n","\n","    # magnitude spectrogram\n","    mag = np.abs(linear)  # (1+n_fft//2, T)\n","\n","    # mel spectrogram\n","    mel_basis = librosa.filters.mel(hp.sr, hp.n_fft, hp.n_mels)  # (n_mels, 1+n_fft//2)\n","    mel = np.dot(mel_basis, mag)  # (n_mels, t)\n","\n","    # to decibel\n","    mel = 20 * np.log10(np.maximum(1e-5, mel))\n","    mag = 20 * np.log10(np.maximum(1e-5, mag))\n","\n","    # normalize\n","    mel = np.clip((mel - hp.ref_db + hp.max_db) / hp.max_db, 1e-8, 1)\n","    mag = np.clip((mag - hp.ref_db + hp.max_db) / hp.max_db, 1e-8, 1)\n","\n","    # Transpose\n","    mel = mel.T.astype(np.float32)  # (T, n_mels)\n","    mag = mag.T.astype(np.float32)  # (T, 1+n_fft//2)\n","\n","    return mel, mag\n","\n","def spectrogram2wav(mag):\n","    '''# Generate wave file from linear magnitude spectrogram\n","\n","    Args:\n","      mag: A numpy array of (T, 1+n_fft//2)\n","\n","    Returns:\n","      wav: A 1-D numpy array.\n","    '''\n","    # transpose\n","    mag = mag.T\n","\n","    # de-noramlize\n","    mag = (np.clip(mag, 0, 1) * hp.max_db) - hp.max_db + hp.ref_db\n","\n","    # to amplitude\n","    mag = np.power(10.0, mag * 0.05)\n","\n","    # wav reconstruction\n","    wav = griffin_lim(mag**hp.power)\n","\n","    # de-preemphasis\n","    wav = signal.lfilter([1], [1, -hp.preemphasis], wav)\n","\n","    # trim\n","    wav, _ = librosa.effects.trim(wav)\n","\n","    return wav.astype(np.float32)\n","\n","def griffin_lim(spectrogram):\n","    '''Applies Griffin-Lim's raw.'''\n","    X_best = copy.deepcopy(spectrogram)\n","    for i in range(hp.n_iter):\n","        X_t = invert_spectrogram(X_best)\n","        est = librosa.stft(X_t, hp.n_fft, hp.hop_length, win_length=hp.win_length)\n","        phase = est / np.maximum(1e-8, np.abs(est))\n","        X_best = spectrogram * phase\n","    X_t = invert_spectrogram(X_best)\n","    y = np.real(X_t)\n","\n","    return y\n","\n","def invert_spectrogram(spectrogram):\n","    '''Applies inverse fft.\n","    Args:\n","      spectrogram: [1+n_fft//2, t]\n","    '''\n","    return librosa.istft(spectrogram, hp.hop_length, win_length=hp.win_length, window=\"hann\")\n","\n","def plot_alignment(alignment, gs, dir=hp.logdir):\n","    \"\"\"Plots the alignment.\n","\n","    Args:\n","      alignment: A numpy array with shape of (encoder_steps, decoder_steps)\n","      gs: (int) global step.\n","      dir: Output path.\n","    \"\"\"\n","    if not os.path.exists(dir): os.mkdir(dir)\n","\n","    fig, ax = plt.subplots()\n","    im = ax.imshow(alignment)\n","\n","    fig.colorbar(im)\n","    plt.title('{} Steps'.format(gs))\n","    plt.savefig('{}/alignment_{}.png'.format(dir, gs), format='png')\n","    plt.close(fig)\n","\n","def guided_attention(g=0.2):\n","    '''Guided attention. Refer to page 3 on the paper.'''\n","    W = np.zeros((hp.max_N, hp.max_T), dtype=np.float32)\n","    for n_pos in range(W.shape[0]):\n","        for t_pos in range(W.shape[1]):\n","            W[n_pos, t_pos] = 1 - np.exp(-(t_pos / float(hp.max_T) - n_pos / float(hp.max_N)) ** 2 / (2 * g * g))\n","    return W\n","\n","def learning_rate_decay(init_lr, global_step, warmup_steps = 4000.0):\n","    '''Noam scheme from tensor2tensor'''\n","    step = tf.to_float(global_step + 1)\n","    return init_lr * warmup_steps**0.5 * tf.minimum(step * warmup_steps**-1.5, step**-0.5)\n","\n","def load_spectrograms(fpath):\n","    '''Read the wave file in `fpath`\n","    and extracts spectrograms'''\n","\n","    fname = os.path.basename(fpath)\n","    mel, mag = get_spectrograms(fpath)\n","    t = mel.shape[0]\n","\n","    # Marginal padding for reduction shape sync.\n","    num_paddings = hp.r - (t % hp.r) if t % hp.r != 0 else 0\n","    mel = np.pad(mel, [[0, num_paddings], [0, 0]], mode=\"constant\")\n","    mag = np.pad(mag, [[0, num_paddings], [0, 0]], mode=\"constant\")\n","\n","    # Reduction\n","    mel = mel[::hp.r, :]\n","    return fname, mel, mag\n","\n"],"execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c854effdd14e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperparams\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperparams'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]}]}